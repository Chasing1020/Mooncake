<div align="center">
<h1>Mooncake</h1>
<h3>A Flexible Framework for Boost LLM Inference Efficiency</h3>
  <strong><a href="#show-cases">ðŸ”¥ Show Cases</a> | <a href="#quick-start">ðŸš€ Quick Start</a> | <a href="#tutorial">ðŸ“ƒ Tutorial</a> | <a href="https://github.com/kvcache-ai/ktransformers/discussions">ðŸ’¬  Discussion </a> </strong>
</div>

<h2 id="intro">ðŸŽ‰ Introduction</h2>

**Mooncake** is an inference acceleration system for large language models (LLMs) with long context. By disaggregating prefill with decoding phases effectively, hardware resources of inference cluster (i.e. CPU, acceleration devices, and memory) are better utilized. 
<br/><br/>
**Mooncake** has been deployed in Kimi (Moonshot Inc.). It processes 115% and 107% more requests than previous systems on NVIDIA A800 and H800 clusters, respectively.
<br/><br/>
To learn more about Mooncake, you can see our paper [arXiv 2407.00079](https://arxiv.org/abs/2407.00079).

![mooncake.png](doc/assets/mooncake.png)

<h2 id="show-cases">ðŸ”¥ Show Cases</h2>
Comparing Mooncake Transfer Engine with Gloo (used by Distributed PyTorch) and TCP, Mooncake Transfer Engine has the lowest I/O latency.
<br/><br/>
With 40 GB of data (equivalent to the size of the KVCache generated by 128k tokens in the LLaMA3-70B model), Mooncake Transfer Engine delivers up to 87 GB/s and 190 GB/s of bandwidth in 4Ã—200 Gbps and 8Ã—400 Gbps RoCE networks respectively, which are about 2.4x and 4.6x faster than the TCP protocol.

![transfer-engine-performance.png](doc/assets/transfer-engine-performance.png)

<h2 id="quick-start">ðŸš€ Quick Start</h2>

### Preparation
In order to install and use Mooncake, some preparation is required.
- Linux-x86_64 with gcc, g++ (9.4+) and cmake (3.16+).
- RDMA Driver & SDK (e.g., Mellanox OFED).
  > If your device's vendor does not provide driver & SDK, you can try to install dependencies by the following command: 
  > ```bash
  > # For Debian/Ubuntu
  > sudo apt-get install libibverbs-dev
  > # For CentOS
  > sudo yum install rdma-core-devel
  > ```
- Python (3.10 or above)

In addition, to support more features of Mooncake Transfer Engine, we *recommand* you to install the following components:

- CUDA 12.1 and above, including CUFILE library, if you want to build with `-DUSE_CUDA`. You may install them from [here](https://developer.nvidia.com/cuda-downloads). 
- Go 1.20+, if you want to build with `-DWITH_P2P_STORE`. You may download it from [here](https://go.dev/dl/).
- Rust Toolclain, if you want to build with `-DWITH_WITH_RUST_EXAMPLE`.

### Installation
> Detailed guide is [here](doc/en/build.md).
1. Init source code
   ```bash
   git clone https://github.com/kvcache-ai/mooncake-dev.git
   cd mooncake
   git checkout v0.1
   ```

   > The development branch often involves large changes, so do not use the clients compiled in the "development branch" for the production environment.

2. Install dependencies
   ```bash
   bash dependencies.sh
   ```

3. Compile Mooncake
   ```bash
   mkdir build
   cd build
   cmake ..
   make -j
   ```

### Demo Program
We provide a simple command-line program that you can run for testing Mooncake Transfer Engine. The detailed description is [here (Chinese only)](doc/zh/run-examples.md).

#### Run Example over RDMA
```bash
# Begin from root of your cloned repo!

# 1. Start the etcd server
etcd --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://localhost:2379
# You may need to terminate other etcd processes before running the above command

# 2. Run the server side
cd build/mooncake-transfer-engine/example
./transfer_engine_bench --mode=target \
                        --metadata_server=localhost:2379 \
                        --local_server_name=localhost:12345 \
                        --device_name=erdma_0

# 3. Run the client side
cd build/mooncake-transfer-engine/example
./transfer_engine_bench --mode=initiator \
                        --metadata_server=localhost:2379 \
                        --segment_id=localhost:12345 \
                        --local_server_name=localhost:12346 \
                        --device_name=erdma_1
```
It features the following arguments:
- `--metadata_server` (required): IP and port of etcd server, which holds the metadata of Transfer Engine.
- `--local_server_name` (required): Local IP/Hostname and port. Other nodes in this cluster may contact with this node using this IP/Hostname and port.
- `--segment_id` (required in client side): Name of destination segment for transfer. It should be exactly the same as `--local_server_name` of the server side.
- `--device_name` (required): RDMA device name to use.

#### Run Example over TCP
```bash
# Begin from root of your cloned repo!

# 1. Start the etcd server
etcd --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://localhost:2379
# You may need to terminate other etcd processes before running the above command

# 2. Run the server side
cd build/mooncake-transfer-engine/example
./transfer_engine_bench --mode=target \
                        --metadata_server=localhost:2379 \
                        --local_server_name=localhost:12345 \
                        --protocol=tcp

# 3. Run the client side
cd build/mooncake-transfer-engine/example
./transfer_engine_bench --mode=initiator \
                        --metadata_server=localhost:2379 \
                        --segment_id=localhost:12345 \
                        --local_server_name=localhost:12346 \
                        --protocol=tcp
```

### P2P Store
The use guide of Mooncake P2P Store is [here (Chinese only)](doc/zh/run-examples.md).

### vLLM Integration
The use guide of vLLM Integration is [here (Chinese only)](doc/zh/run-examples.md).

## Troubleshooting 
If you failed to perform data transfer in your platform, we recommend you to check out the [trobleshooting guide](doc/zh/troubleshooting.md) before asking us.

## Contribute
We welcome contributions from the community! If you have any suggestions or find issues, please submit them via GitHub Issues and Pull Requests.
